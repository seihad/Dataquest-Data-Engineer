{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Project: Analyzing Wikipedia Pages"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "the goal of the project is to search for all occurences of a string in allof the files, providing a case-insensitive option to the search, and to refine the result by providing the specific locations of the files"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Introducing Wikipedia Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "listing the files in wiki folder"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "import os\n",
    "file_names = os.listdir(\"wiki\")\n",
    "for i in range(3):\n",
    "    print(file_names[i])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Ronald_McCaffer.html\n",
      "IwakiIshikawa_Station.html\n",
      "Communities_of_Tulu_Nadu.html\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "counting and displaying the number of files in the wiki folder"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "num_files = len(file_names)\n",
    "print(num_files)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "999\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "read the first line in the wiki folder and printing its contents"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "folder_name = \"wiki\"\n",
    "file_name_first = file_names[0]\n",
    "with open(os.path.join(folder_name, file_name_first)) as f:\n",
    "    lines = [line for line in f.readlines()]\n",
    "print(lines[1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<html class=\"client-nojs\" lang=\"en\" dir=\"ltr\">\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Adding the MapReduce Framework"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "the code for mapreduce"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "import math\n",
    "import functools\n",
    "from multiprocess import Pool\n",
    "\n",
    "def make_chunks(data, num_chunks):\n",
    "    chunk_size = math.ceil(len(data) / num_chunks)\n",
    "    return [data[i:i+chunk_size] for i in range(0, len(data), chunk_size)]\n",
    "\n",
    "def map_reduce(data, num_processes, mapper, reducer):\n",
    "    chunks = make_chunks(data, num_processes)\n",
    "    pool = Pool(num_processes)\n",
    "    chunk_results = pool.map(mapper, chunks)\n",
    "    return functools.reduce(reducer, chunk_results)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "counting the total number of lines in all files"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "def map_line_count(file_names):\n",
    "    total = 0\n",
    "    for fn in file_names:\n",
    "        with open(os.path.join(\"wiki\", fn)) as f:\n",
    "            total += len(f.readlines())\n",
    "    return total\n",
    "    \n",
    "def reduce_line_count(count1, count2):\n",
    "    return count1 + count2\n",
    "\n",
    "results = map_reduce(file_names, 8, map_line_count, reduce_line_count)\n",
    "print(results)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "499797\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Grep Exact Match"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "using mapreduce to create a function that given a string, creates a dictionary where the keys are the file names and the values are lists with all line indexes that contain the string"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "def map_grep(file_names):\n",
    "    results = {}\n",
    "    for fn in file_names:\n",
    "        with open(fn) as f:\n",
    "            lines = [line for line in f.readlines()]\n",
    "        for line_index, line in enumerate(lines):\n",
    "            if target in line:\n",
    "                if fn not in results:\n",
    "                    results[fn] = []\n",
    "                results[fn].append(line_index)\n",
    "    return results\n",
    "\n",
    "def reduce_grep(lines1, lines2):\n",
    "    lines1.update(lines2)\n",
    "    return lines1\n",
    "\n",
    "def mapreduce_grep(path, num_processes):\n",
    "    file_names = [os.path.join(path, fn) for fn in os.listdir(path)]\n",
    "    return map_reduce(file_names, num_processes,  map_grep, reduce_grep)\n",
    "\n",
    "target = \"data\"\n",
    "data_occurrences = mapreduce_grep(\"wiki\", 8)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Grep Case Insensitive"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "creating a function that creates a dictionary. the keys are the filenames and the values are lists with all indices that contain the given string"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "def map_grep_insensitive(file_names):\n",
    "    results = {}\n",
    "    for fn in file_names:\n",
    "        with open(fn) as f:\n",
    "            lines = [line.lower() for line in f.readlines()]\n",
    "        for line_index, line in enumerate(lines):\n",
    "            if target.lower() in line:\n",
    "                if fn not in results:\n",
    "                    results[fn] = []\n",
    "                results[fn].append(line_index)\n",
    "    return results\n",
    "\n",
    "def mapreduce_grep_insensitive(path, num_processes):\n",
    "    file_names = [os.path.join(path, fn) for fn in os.listdir(path)]\n",
    "    return map_reduce(file_names, num_processes,  map_grep_insensitive, reduce_grep)\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "finding all occurences of the string \"data\""
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "target = \"data\"\n",
    "new_data_occurrences = mapreduce_grep_insensitive(\"wiki\", 8)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Checking the Implementation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "storing the results of the search for string \"data\" with both versions of the algorithms into variables"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "for fn in new_data_occurrences:\n",
    "    if fn not in data_occurrences:\n",
    "        print(\"Found {} new matches on file {}\".format(len(new_data_occurrences[fn]), fn))\n",
    "    elif len(new_data_occurrences[fn]) > len(data_occurrences[fn]):\n",
    "        print(\"Found {} new matches on file {}\".format(len(new_data_occurrences[fn]) - len(data_occurrences[fn]), fn))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 1 new matches on file wiki/Tim_Spencer_(singer).html\n",
      "Found 1 new matches on file wiki/Embraer_Unidade_GaviC3A3o_Peixoto_Airport.html\n",
      "Found 1 new matches on file wiki/Lower_Blackburn_Grade_Bridge.html\n",
      "Found 1 new matches on file wiki/HD_90156.html\n",
      "Found 2 new matches on file wiki/Kate_Harwood.html\n",
      "Found 1 new matches on file wiki/Doumanaba.html\n",
      "Found 6 new matches on file wiki/Dragnet_(franchise).html\n",
      "Found 1 new matches on file wiki/Boardman_Township_Mahoning_County_Ohio.html\n",
      "Found 1 new matches on file wiki/Brownfield_(software_development).html\n",
      "Found 1 new matches on file wiki/Kattukukke.html\n",
      "Found 2 new matches on file wiki/The_Audacity_to_Podcast.html\n",
      "Found 1 new matches on file wiki/Derek_Acorah.html\n",
      "Found 1 new matches on file wiki/Lis_LC3B8wert.html\n",
      "Found 1 new matches on file wiki/KMTZ.html\n",
      "Found 1 new matches on file wiki/Battle_of_Wattignies.html\n",
      "Found 1 new matches on file wiki/Manhattan_Murder_Mystery.html\n",
      "Found 2 new matches on file wiki/Shpolskii_matrix.html\n",
      "Found 1 new matches on file wiki/The_Future_(film).html\n",
      "Found 1 new matches on file wiki/Lake_County_Examiner.html\n",
      "Found 1 new matches on file wiki/C11orf30.html\n",
      "Found 2 new matches on file wiki/Tomohiko_ItC58D_(director).html\n",
      "Found 1 new matches on file wiki/King_Parker_House.html\n",
      "Found 1 new matches on file wiki/Vojin_C486etkoviC487.html\n",
      "Found 1 new matches on file wiki/Weiser_River.html\n",
      "Found 1 new matches on file wiki/Copamyntis_infusella.html\n",
      "Found 1 new matches on file wiki/Saravan_Gilan.html\n",
      "Found 1 new matches on file wiki/Wilhelm_Wagenfeld_House.html\n",
      "Found 1 new matches on file wiki/Swathi_Chinukulu.html\n",
      "Found 3 new matches on file wiki/Code_page_1023.html\n",
      "Found 1 new matches on file wiki/Meleh_Kabude_Sofla.html\n",
      "Found 1 new matches on file wiki/Acceptance_(Heroes).html\n",
      "Found 1 new matches on file wiki/Antibiotic_use_in_livestock.html\n",
      "Found 1 new matches on file wiki/Pushkar.html\n",
      "Found 1 new matches on file wiki/Pictogram.html\n",
      "Found 2 new matches on file wiki/Viva_Villa.html\n",
      "Found 1 new matches on file wiki/Bias.html\n",
      "Found 1 new matches on file wiki/Panchamrutham.html\n",
      "Found 1 new matches on file wiki/Typhoon_Hester_(1952).html\n",
      "Found 1 new matches on file wiki/Daniel_Cerone.html\n",
      "Found 1 new matches on file wiki/Teiji_Ito.html\n",
      "Found 1 new matches on file wiki/Kokan_Colony.html\n",
      "Found 1 new matches on file wiki/PTPRS.html\n",
      "Found 1 new matches on file wiki/L._Fry.html\n",
      "Found 1 new matches on file wiki/Holly_Golightly_(comics).html\n",
      "Found 1 new matches on file wiki/Old_Mill_Creek_Illinois.html\n",
      "Found 1 new matches on file wiki/Morgana_King.html\n",
      "Found 1 new matches on file wiki/Harry_Hill_Bandholtz.html\n",
      "Found 1 new matches on file wiki/Imperial_Venus_(film).html\n",
      "Found 1 new matches on file wiki/Dewoitine_D.21.html\n",
      "Found 1 new matches on file wiki/Appa_(film).html\n",
      "Found 1 new matches on file wiki/Syngenor.html\n",
      "Found 1 new matches on file wiki/Shabbir_Kumar.html\n",
      "Found 1 new matches on file wiki/Bibiana_Beglau.html\n",
      "Found 2 new matches on file wiki/Kim_Yonghwa.html\n",
      "Found 1 new matches on file wiki/WLSR.html\n",
      "Found 1 new matches on file wiki/Kul_Gul.html\n",
      "Found 1 new matches on file wiki/Don_Raye.html\n",
      "Found 1 new matches on file wiki/Amborella.html\n",
      "Found 1 new matches on file wiki/Don_Parsons_(ice_hockey).html\n",
      "Found 1 new matches on file wiki/Ordinary_Virginia.html\n",
      "Found 1 new matches on file wiki/Bahmanabade_Olya.html\n",
      "Found 1 new matches on file wiki/C389cole_des_Mines_de_Douai.html\n",
      "Found 3 new matches on file wiki/Maniitsoq_structure.html\n",
      "Found 7 new matches on file wiki/List_of_people_from_Bangor_Maine.html\n",
      "Found 1 new matches on file wiki/Craig_Chester.html\n",
      "Found 1 new matches on file wiki/Danish_Maritime_Safety_Administration.html\n",
      "Found 1 new matches on file wiki/Avengers_Academy.html\n",
      "Found 1 new matches on file wiki/Companys_procC3A9s_a_Catalunya.html\n",
      "Found 2 new matches on file wiki/Jules_Verne_ATV.html\n",
      "Found 1 new matches on file wiki/Ingrid_GuimarC3A3es.html\n",
      "Found 1 new matches on file wiki/Colchester_Village_Historic_District.html\n",
      "Found 1 new matches on file wiki/Frost_Township_Michigan.html\n",
      "Found 1 new matches on file wiki/Medicago_murex.html\n",
      "Found 1 new matches on file wiki/Failing_Office_Building.html\n",
      "Found 1 new matches on file wiki/Jazz_in_Turkey.html\n",
      "Found 1 new matches on file wiki/83_(number).html\n",
      "Found 2 new matches on file wiki/Claire_Danes.html\n",
      "Found 1 new matches on file wiki/Blue_SWAT.html\n",
      "Found 1 new matches on file wiki/Rudy_The_Rudy_Giuliani_Story.html\n",
      "Found 1 new matches on file wiki/Cryptographic_primitive.html\n",
      "Found 1 new matches on file wiki/Rally_for_Democracy_and_Progress_(Benin).html\n",
      "Found 1 new matches on file wiki/Shoreyjehye_Do.html\n",
      "Found 1 new matches on file wiki/1953E2809354_FA_Cup_qualifying_rounds.html\n",
      "Found 1 new matches on file wiki/Julien_Boisselier.html\n",
      "Found 1 new matches on file wiki/CurtissWright_Hangar_(Columbia_South_Carolina).html\n",
      "Found 1 new matches on file wiki/Dean_Kukan.html\n",
      "Found 1 new matches on file wiki/Exploratorium_(film).html\n",
      "Found 1 new matches on file wiki/Table_Point_Formation.html\n",
      "Found 1 new matches on file wiki/Wilson_Global_Explorer.html\n",
      "Found 1 new matches on file wiki/Alex_Kurtzman.html\n",
      "Found 1 new matches on file wiki/WintersWimberley_House.html\n",
      "Found 1 new matches on file wiki/Benny_Lee.html\n",
      "Found 2 new matches on file wiki/List_of_Spaghetti_Western_films.html\n",
      "Found 1 new matches on file wiki/Claudia_Neidig.html\n",
      "Found 1 new matches on file wiki/Smilax_laurifolia.html\n",
      "Found 1 new matches on file wiki/Qalat_Kat.html\n",
      "Found 2 new matches on file wiki/Taipa_HousesE28093Museum.html\n",
      "Found 1 new matches on file wiki/Mirisah.html\n",
      "Found 1 new matches on file wiki/Westchester_Los_Angeles.html\n",
      "Found 1 new matches on file wiki/Sahanpur.html\n",
      "Found 1 new matches on file wiki/Ek_Dil_Sau_Afsane.html\n",
      "Found 1 new matches on file wiki/Sol_Eclipse.html\n",
      "Found 1 new matches on file wiki/Devil_on_Horseback.html\n",
      "Found 1 new matches on file wiki/Gulliver_Mickey.html\n",
      "Found 1 new matches on file wiki/The_Gentleman_Without_a_Residence_(1915_film).html\n",
      "Found 1 new matches on file wiki/Mudramothiram.html\n",
      "Found 1 new matches on file wiki/Functoid.html\n",
      "Found 2 new matches on file wiki/Gordon_Bau.html\n",
      "Found 2 new matches on file wiki/Agaritine_gammaglutamyltransferase.html\n",
      "Found 1 new matches on file wiki/Oldfield_Baby_Great_Lakes.html\n",
      "Found 1 new matches on file wiki/Jonathan_A._Goldstein.html\n",
      "Found 4 new matches on file wiki/List_of_molecular_graphics_systems.html\n",
      "Found 1 new matches on file wiki/SalemAuburn_Streets_Historic_District.html\n",
      "Found 1 new matches on file wiki/Taylor_Williamson.html\n",
      "Found 1 new matches on file wiki/Filip_Pyrochta.html\n",
      "Found 1 new matches on file wiki/Furto_di_sera_bel_colpo_si_spera.html\n",
      "Found 1 new matches on file wiki/Urs_Burkart.html\n",
      "Found 1 new matches on file wiki/List_of_Uzbek_films_of_2014.html\n",
      "Found 1 new matches on file wiki/A_Beautiful_Valley.html\n",
      "Found 1 new matches on file wiki/Golabkhvaran.html\n",
      "Found 1 new matches on file wiki/Cobble_Hill_Brooklyn.html\n",
      "Found 1 new matches on file wiki/Tropical_sprue.html\n",
      "Found 1 new matches on file wiki/Foulonia.html\n",
      "Found 1 new matches on file wiki/Jon_Mullich.html\n",
      "Found 2 new matches on file wiki/Precorrin6A_reductase.html\n",
      "Found 1 new matches on file wiki/Demographics_of_American_Samoa.html\n",
      "Found 1 new matches on file wiki/West_Park_Bridge.html\n",
      "Found 1 new matches on file wiki/Jack_Goes_Home.html\n",
      "Found 1 new matches on file wiki/Hayateumi_Hidehito.html\n",
      "Found 1 new matches on file wiki/Morning_Glory_(2010_film).html\n",
      "Found 1 new matches on file wiki/Camp_Nelson_Confederate_Cemetery.html\n",
      "Found 1 new matches on file wiki/Nuno_Leal_Maia.html\n",
      "Found 1 new matches on file wiki/Roxbury_Presbyterian_Church.html\n",
      "Found 1 new matches on file wiki/Peter_Collingwood.html\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "modifying the mapper function so that it returns a list of pairs with all occurences"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.2",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}